{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detectron2 Instance Segmentation Inference of AVA DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, DatasetEvaluators\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "import os \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json \n",
    "from pycocotools import mask\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.clear()\n",
    "Data_Resister_training=\"../Data_NoTemporal_cleaned_orig/train_xworld\";\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(Data_Resister_training,{}, '../Data_NoTemporal_cleaned_orig/train_xworld.json', Path(\"../Data_NoTemporal_cleaned_orig/train_xworld\"))\n",
    "\n",
    "metadata = MetadataCatalog.get(Data_Resister_training)\n",
    "dataset_train = DatasetCatalog.get(Data_Resister_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.MODEL.ROI_MASK_HEAD.NAME='MaskRCNNConvUpsampleHead_multi'\n",
    "config_name = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"#\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\" #\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\" # \n",
    "cfg.merge_from_file(model_zoo.get_config_file(config_name))\n",
    "cfg.MODEL.ROI_MASK_HEAD.NUM_CONV=4\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"../detectron_results/segmentation_101_multihead/model_0009999.pth\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.MODEL.DEVICE='cpu'\n",
    "cfg.MODEL.MASK_ON = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Following function is from detectron2 official github page -\n",
    "\n",
    "https://github.com/facebookresearch/detectron2/blob/main/detectron2/evaluation/coco_evaluation.py\n",
    "\n",
    "'''\n",
    "\n",
    "from detectron2.structures import BoxMode\n",
    "import pycocotools.mask as mask_util\n",
    "\n",
    "def instances_to_coco_json(instances, img_id):\n",
    "    \"\"\"\n",
    "    Dump an \"Instances\" object to a COCO-format json that's used for evaluation.\n",
    "    Args:\n",
    "        instances (Instances):\n",
    "        img_id (int): the image id\n",
    "    Returns:\n",
    "        list[dict]: list of json annotations in COCO format.\n",
    "    \"\"\"\n",
    "    num_instance = len(instances)\n",
    "    if num_instance == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = instances.pred_boxes.tensor.numpy()\n",
    "    boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n",
    "    boxes = boxes.tolist()\n",
    "    scores = instances.scores.tolist()\n",
    "    classes = instances.pred_classes.tolist()\n",
    "    classes = [c + 1 for c in classes]\n",
    "\n",
    "    has_mask = instances.has(\"pred_masks\")\n",
    "    if has_mask:\n",
    "      \n",
    "        rles = [\n",
    "            mask_util.encode(np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n",
    "            for mask in instances.pred_masks\n",
    "        ]\n",
    "        for rle in rles:\n",
    "            \n",
    "            rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
    "\n",
    "    results = []\n",
    "    for k in range(num_instance):\n",
    "        result = {\n",
    "            \"image_id\": int(img_id),\n",
    "            \"category_id\": classes[k],\n",
    "            \"bbox\": [float(b) for b in boxes[k]],\n",
    "            \"score\": scores[k],\n",
    "        }\n",
    "        if has_mask:\n",
    "            result[\"segmentation\"] = rles[k]\n",
    "     \n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ann = {}\n",
    "\n",
    "# Create predictor\n",
    "predictor = DefaultPredictor(cfg)\n",
    "all_results=[]\n",
    "\n",
    "for file in os.listdir('../Data_NoTemporal/test_xworld/'):\n",
    "    im = cv2.imread('../Data_NoTemporal/test_xworld/'+file)\n",
    "    \n",
    "    # Make prediction\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    if outputs['instances'].pred_masks.numel() == 0:\n",
    "        continue \n",
    "\n",
    "    else:\n",
    "        coco_results= instances_to_coco_json(outputs['instances'].to('cpu'), file.split('.')[0])\n",
    "        all_results.extend(coco_results)\n",
    "\n",
    "print(all_results)\n",
    "# Save the encoded data to a JSON file\n",
    "with open('segmentation.json', 'w') as f:\n",
    "    json.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im = cv2.imread(\"../Data_NoTemporal/test_xworld/020000006000.jpg\")\n",
    "plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Make prediction\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs['instances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['instances'].pred_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(im[:, :, ::-1], metadata, scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.figure(figsize = (14, 10))\n",
    "plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot loss functions'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "\n",
    "# json_files = [\"segmentation_res_50_multihead/metrics.json\", \"segmentation_101_multihead/metrics.json\", \"renet-50-bam-residual-focaltaversky/metrics.json\"]\n",
    "# colors = ['c', 'm', 'y']\n",
    "# labels = ['MHA-MaskRCNN_ResNet50_F.Tversky', 'MHA-MaskRCNN_ResNet101_F.Tversky', 'BAMS-MaskRCNN_ResNet50_F.Tversky']\n",
    "\n",
    "# metrics = ['loss_mask', 'total_loss',  'loss_box_reg', 'fast_rcnn/cls_accuracy','mask_rcnn/false_negative', 'mask_rcnn/accuracy']\n",
    "\n",
    "# for metric in metrics:\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     for i, file_name in enumerate(json_files):\n",
    "#         metric_values = []\n",
    "#         with open('../detectron_results/'+file_name, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 data = json.loads(line)\n",
    "#                 if metric in data:\n",
    "#                     metric_values.append(data[metric])\n",
    "#                 else:\n",
    "#                     metric_values.append(np.nan)  # Append NaN if key does not exist\n",
    "        \n",
    "#         plt.plot(metric_values, label=labels[i], color=colors[i])\n",
    "#     plt.title(metric)\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
